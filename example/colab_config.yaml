# Config template to input parameters into dnntime
meta:
    user_interface: 'console'  # either 'console' (default) or 'notebook'
    datetime_column: 'time'
    target_column: 'total load actual'
etl1:
    description: 'Extract Data from Source'
    extract:
        alias: 'Original'   # If alias is blank, then default will be 'Extract' with proper format
        file_path: 'energy_dataset.csv'
        delineator: ','
    univariate: True
etl2:
    description: 'Preprocessing I (Cleaning)'
    clean:  # this entire block can be omitted if 'auto_clean' is not needed
        time_interval: 'hourly'
        timezone: 'Europe/Madrid'
        allow_negatives: True  # set to Fase if negative values are prohibited, hence set to NaN
        all_numeric: True  # convert entire DataFrame into float64 (if not already done so)
        nan_fill_type: 'linear'  # leave '' to not fill, see: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html
        output_type: 'reg'  # regression 'reg' or classication 'class'
eda1:
    description: 'EDA I (General)'
    general:
        title: 'PJME Regional Power Demand Time-Series'
        x_label: 'Datetime'
        y_label: 'Total Demand (MW)'
        figsize: (24, 8)
        # plotly: True
eda2:
    description: 'EDA II (Time-Series Stats)'
    statistical:
        title: 'Total Electricity Demand'
        x_label: 'Datetime'
        y_label: 'Total Demand (MW)'
        confidence_interval: 0.95
        figsize: (20, 6)
        # plotly: True
etl3:
    description: 'Preprocessing II (Transformations)'
    transform1:
        alias: 'Box-Cox Standardized'
        method: 'box-cox'
        standardize: True
    transform2:
        alias: 'Deseasonalize'
        method: 'deseasonalize'
        decomposition_model: 'additive'
etl4:
    description: 'Preprocessing III (Make Supervised)'
    supervise:
        training_period: 'biweek'  # walk-forward validation input timesteps
        forecast_period: 'day'  # walk-forward validation output timesteps
        validation_set:  'biweek'  # size of the validation set, taken from period prior to 
        test_set: 'month'  # size of the test set, taken from the last <input> of dataset
        max_gap: 0.01
model:
    description: 'Model Search (DNNs)'
    enable_gpu: True
    verbose: 1  # description for model 'fit' and 'evaluate'
    score_type: 'rmse'
    # OPTION 1) Run all DNN models with common hyperparameters specified here
    dnn:
        model_type: 'all'
        epochs: 10
        batch_size: 512
        number_layers: 3
        number_units: 256   # number of units per layer
        dropout_rate: 0.25   # dropout rate
        optimizer: 'adam'
        objective_function: 'mse'  # the loss value minimized by the dnn model
    # OPTION 2) Run each DNN model invidually with configurable parameters for each one
    # In this default setup, both OPTION 1) and 2) will produce the same results
    # dnn1:
    #     alias: 'RNN'
    #     model_type: 'rnn'
    #     epochs: 10
    #     batch_size: 512
    #     number_layers: 3
    #     number_units: 256   # number of units per layer
    #     dropout_rate: 0.25   # dropout rate
    #     optimizer: 'adam'
    #     objective_function: 'mse'  # the loss value minimized by the dnn model
    # dnn2:
    #     alias: 'LSTM'
    #     model_type: 'lstm'
    #     epochs: 10
    #     batch_size: 512
    #     number_layers: 3
    #     number_units: 256   # number of units per layer
    #     dropout_rate: 0.25   # dropout rate
    #     optimizer: 'adam'
    #     objective_function: 'mse'  # the loss value minimized by the dnn model
    # dnn3:
    #     alias: 'GRU'
    #     model_type: 'gru'
    #     epochs: 10
    #     batch_size: 512
    #     number_layers: 3
    #     number_units: 256   # number of units per layer
    #     dropout_rate: 0.25   # dropout rate
    #     optimizer: 'adam'
    #     objective_function: 'mse'  # the loss value minimized by the dnn model
    # dnn4:
    #     alias: 'CONVLSTM'
    #     model_type: 'convlstm'
    #     epochs: 10
    #     batch_size: 512
    #     number_layers: 3
    #     number_units: 256   # number of units per layer
    #     dropout_rate: 0.25   # dropout rate
    #     optimizer: 'adam'
    #     objective_function: 'mse'  # the loss value minimized by the dnn model